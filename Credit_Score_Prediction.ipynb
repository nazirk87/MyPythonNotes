{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"C:/Users/Nagi/Documents/Hackathon_20190916/Hackathon/CreditScore/CreditScore_train.csv\")\n",
    "test_df=pd.read_csv(\"C:/Users/Nagi/Documents/Hackathon_20190916/Hackathon/CreditScore/CreditScore_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : rows 80000  and columns 305\n",
      "Test size : rows 20000  and columns 305\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size : rows\",train_df.shape[0],\" and columns\",train_df.shape[1])\n",
    "print(\"Test size : rows\",test_df.shape[0],\" and columns\",test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007', 'x008', 'x009',\n",
       "       'x010',\n",
       "       ...\n",
       "       'x296', 'x297', 'x298', 'x299', 'x300', 'x301', 'x302', 'x303', 'x304',\n",
       "       'y'],\n",
       "      dtype='object', length=305)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.difference(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.difference(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_df[\"source\"] = \"train\"\n",
    "test_df[\"source\"] = \"test\"\n",
    "df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source     object\n",
       "x001        int64\n",
       "x002      float64\n",
       "x003      float64\n",
       "x004      float64\n",
       "x005      float64\n",
       "x006        int64\n",
       "x007        int64\n",
       "x008        int64\n",
       "x009        int64\n",
       "x010        int64\n",
       "x011        int64\n",
       "x012        int64\n",
       "x013        int64\n",
       "x014        int64\n",
       "x015        int64\n",
       "x016        int64\n",
       "x017        int64\n",
       "x018        int64\n",
       "x019        int64\n",
       "x020        int64\n",
       "x021        int64\n",
       "x022        int64\n",
       "x023        int64\n",
       "x024        int64\n",
       "x025        int64\n",
       "x026        int64\n",
       "x027        int64\n",
       "x028        int64\n",
       "x029        int64\n",
       "           ...   \n",
       "x276        int64\n",
       "x277        int64\n",
       "x278        int64\n",
       "x279        int64\n",
       "x280        int64\n",
       "x281        int64\n",
       "x282        int64\n",
       "x283        int64\n",
       "x284        int64\n",
       "x285        int64\n",
       "x286        int64\n",
       "x287      float64\n",
       "x288      float64\n",
       "x289      float64\n",
       "x290      float64\n",
       "x291        int64\n",
       "x292        int64\n",
       "x293      float64\n",
       "x294        int64\n",
       "x295      float64\n",
       "x296        int64\n",
       "x297      float64\n",
       "x298        int64\n",
       "x299        int64\n",
       "x300        int64\n",
       "x301        int64\n",
       "x302      float64\n",
       "x303        int64\n",
       "x304      float64\n",
       "y         float64\n",
       "Length: 306, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 306)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x001</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.218244e+06</td>\n",
       "      <td>272897.724977</td>\n",
       "      <td>517.0</td>\n",
       "      <td>974363.50000</td>\n",
       "      <td>1.235926e+06</td>\n",
       "      <td>1.445326e+06</td>\n",
       "      <td>1.677197e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x002</th>\n",
       "      <td>78568.0</td>\n",
       "      <td>1.257117e+02</td>\n",
       "      <td>115.785117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.800000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x003</th>\n",
       "      <td>78568.0</td>\n",
       "      <td>2.554124e+01</td>\n",
       "      <td>49.028751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>7.040000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x004</th>\n",
       "      <td>78576.0</td>\n",
       "      <td>6.539321e+01</td>\n",
       "      <td>63.592317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>7.040000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x005</th>\n",
       "      <td>93890.0</td>\n",
       "      <td>1.782385e+02</td>\n",
       "      <td>124.520628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>2.460000e+02</td>\n",
       "      <td>8.270000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x006</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.140400e-01</td>\n",
       "      <td>0.464135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x007</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.940000e-01</td>\n",
       "      <td>1.379378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x008</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.388220e+00</td>\n",
       "      <td>2.282805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.080000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x009</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.192980e+00</td>\n",
       "      <td>2.031083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x010</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.026990e+00</td>\n",
       "      <td>1.713823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x011</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.843240e+00</td>\n",
       "      <td>2.711524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x012</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.607940e+00</td>\n",
       "      <td>2.582390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x013</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.576860e+00</td>\n",
       "      <td>2.609533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x014</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.306830e+00</td>\n",
       "      <td>5.473131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>6.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x015</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.294306e+01</td>\n",
       "      <td>11.957652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.890000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x016</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.089260e+00</td>\n",
       "      <td>4.622082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>8.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x017</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8.853800e+00</td>\n",
       "      <td>9.254211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.620000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x018</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.988200e+00</td>\n",
       "      <td>2.361058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x019</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.147260e+00</td>\n",
       "      <td>1.748446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x020</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.798700e+00</td>\n",
       "      <td>7.829639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.590000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x021</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.283170e+00</td>\n",
       "      <td>3.161361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x022</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.730500e+00</td>\n",
       "      <td>1.120072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x023</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.085840e+00</td>\n",
       "      <td>1.011910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x024</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.733060e+00</td>\n",
       "      <td>7.159681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.290000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x025</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.185200e-01</td>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x026</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.697900e-01</td>\n",
       "      <td>0.495108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x027</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>7.515200e-01</td>\n",
       "      <td>0.432134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x028</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8.018500e-01</td>\n",
       "      <td>1.579586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x029</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.476120e+00</td>\n",
       "      <td>2.036195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x030</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.037540e+00</td>\n",
       "      <td>4.782564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.340000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x276</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.565100e-01</td>\n",
       "      <td>0.939979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x277</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.856100e-01</td>\n",
       "      <td>1.008686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x278</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.488800e-01</td>\n",
       "      <td>1.131413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x279</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.565756e+04</td>\n",
       "      <td>177914.758081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>9.695000e+03</td>\n",
       "      <td>5.381500e+04</td>\n",
       "      <td>1.522472e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x280</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>9.516506e+03</td>\n",
       "      <td>50262.873445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.820000e+02</td>\n",
       "      <td>4.087029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x281</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.614105e+04</td>\n",
       "      <td>170525.864807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.253000e+03</td>\n",
       "      <td>3.570575e+04</td>\n",
       "      <td>1.522406e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x282</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8.658500e-01</td>\n",
       "      <td>0.340815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x283</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8.738400e-01</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x284</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8.841400e-01</td>\n",
       "      <td>0.320059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x285</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.391490e+00</td>\n",
       "      <td>2.682935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x286</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.152600e-01</td>\n",
       "      <td>0.695126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x287</th>\n",
       "      <td>75179.0</td>\n",
       "      <td>3.239309e+00</td>\n",
       "      <td>3.090414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x288</th>\n",
       "      <td>50244.0</td>\n",
       "      <td>5.169799e+01</td>\n",
       "      <td>52.700032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>7.400000e+01</td>\n",
       "      <td>5.290000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x289</th>\n",
       "      <td>50244.0</td>\n",
       "      <td>2.544553e+01</td>\n",
       "      <td>34.674418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>4.650000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x290</th>\n",
       "      <td>50244.0</td>\n",
       "      <td>3.833166e+01</td>\n",
       "      <td>38.882567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.66660</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>4.650000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x291</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.461510e+04</td>\n",
       "      <td>37717.143370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.712800e+04</td>\n",
       "      <td>4.348891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x292</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.839332e+04</td>\n",
       "      <td>164530.463427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.758000e+03</td>\n",
       "      <td>4.333125e+04</td>\n",
       "      <td>1.520793e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x293</th>\n",
       "      <td>48867.0</td>\n",
       "      <td>8.125753e-01</td>\n",
       "      <td>0.321268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64060</td>\n",
       "      <td>8.601000e-01</td>\n",
       "      <td>9.970000e-01</td>\n",
       "      <td>1.839990e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x294</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.795508e+03</td>\n",
       "      <td>17515.777542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.721366e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x295</th>\n",
       "      <td>13467.0</td>\n",
       "      <td>9.013038e-01</td>\n",
       "      <td>0.433850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65635</td>\n",
       "      <td>9.406000e-01</td>\n",
       "      <td>1.140950e+00</td>\n",
       "      <td>1.839990e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x296</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.181960e+04</td>\n",
       "      <td>32264.688940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.295600e+04</td>\n",
       "      <td>2.696702e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x297</th>\n",
       "      <td>41888.0</td>\n",
       "      <td>7.940343e-01</td>\n",
       "      <td>0.288249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63690</td>\n",
       "      <td>8.510000e-01</td>\n",
       "      <td>9.820000e-01</td>\n",
       "      <td>1.303530e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x298</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.433200e-01</td>\n",
       "      <td>0.498122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x299</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.580300e-01</td>\n",
       "      <td>0.496624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x300</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.818300e-01</td>\n",
       "      <td>0.493261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x301</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.062400e-01</td>\n",
       "      <td>0.308146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x302</th>\n",
       "      <td>26931.0</td>\n",
       "      <td>2.948758e+00</td>\n",
       "      <td>2.129430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x303</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.410883e+03</td>\n",
       "      <td>24190.243313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.855370e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x304</th>\n",
       "      <td>18125.0</td>\n",
       "      <td>1.037957e+00</td>\n",
       "      <td>0.330580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97580</td>\n",
       "      <td>1.048600e+00</td>\n",
       "      <td>1.186200e+00</td>\n",
       "      <td>5.156900e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>6.193978e+02</td>\n",
       "      <td>118.357217</td>\n",
       "      <td>300.0</td>\n",
       "      <td>524.00000</td>\n",
       "      <td>5.990000e+02</td>\n",
       "      <td>7.190000e+02</td>\n",
       "      <td>8.390000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         count          mean            std    min           25%  \\\n",
       "x001  100000.0  1.218244e+06  272897.724977  517.0  974363.50000   \n",
       "x002   78568.0  1.257117e+02     115.785117    0.0      32.00000   \n",
       "x003   78568.0  2.554124e+01      49.028751    0.0       3.00000   \n",
       "x004   78576.0  6.539321e+01      63.592317    0.0      19.00000   \n",
       "x005   93890.0  1.782385e+02     124.520628    0.0      87.00000   \n",
       "x006  100000.0  3.140400e-01       0.464135    0.0       0.00000   \n",
       "x007  100000.0  6.940000e-01       1.379378    0.0       0.00000   \n",
       "x008  100000.0  1.388220e+00       2.282805    0.0       0.00000   \n",
       "x009  100000.0  1.192980e+00       2.031083    0.0       0.00000   \n",
       "x010  100000.0  1.026990e+00       1.713823    0.0       0.00000   \n",
       "x011  100000.0  1.843240e+00       2.711524    0.0       0.00000   \n",
       "x012  100000.0  1.607940e+00       2.582390    0.0       0.00000   \n",
       "x013  100000.0  1.576860e+00       2.609533    0.0       0.00000   \n",
       "x014  100000.0  4.306830e+00       5.473131    0.0       0.00000   \n",
       "x015  100000.0  1.294306e+01      11.957652    0.0       4.00000   \n",
       "x016  100000.0  4.089260e+00       4.622082    0.0       1.00000   \n",
       "x017  100000.0  8.853800e+00       9.254211    0.0       2.00000   \n",
       "x018  100000.0  3.988200e+00       2.361058    0.0       2.00000   \n",
       "x019  100000.0  2.147260e+00       1.748446    0.0       1.00000   \n",
       "x020  100000.0  6.798700e+00       7.829639    0.0       1.00000   \n",
       "x021  100000.0  2.283170e+00       3.161361    0.0       0.00000   \n",
       "x022  100000.0  1.730500e+00       1.120072    0.0       1.00000   \n",
       "x023  100000.0  1.085840e+00       1.011910    0.0       0.00000   \n",
       "x024  100000.0  4.733060e+00       7.159681    0.0       1.00000   \n",
       "x025  100000.0  3.185200e-01       0.465905    0.0       0.00000   \n",
       "x026  100000.0  5.697900e-01       0.495108    0.0       0.00000   \n",
       "x027  100000.0  7.515200e-01       0.432134    0.0       1.00000   \n",
       "x028  100000.0  8.018500e-01       1.579586    0.0       0.00000   \n",
       "x029  100000.0  1.476120e+00       2.036195    0.0       0.00000   \n",
       "x030  100000.0  4.037540e+00       4.782564    0.0       1.00000   \n",
       "...        ...           ...            ...    ...           ...   \n",
       "x276  100000.0  2.565100e-01       0.939979    0.0       0.00000   \n",
       "x277  100000.0  2.856100e-01       1.008686    0.0       0.00000   \n",
       "x278  100000.0  3.488800e-01       1.131413    0.0       0.00000   \n",
       "x279  100000.0  6.565756e+04  177914.758081    0.0      34.00000   \n",
       "x280  100000.0  9.516506e+03   50262.873445    0.0       0.00000   \n",
       "x281  100000.0  5.614105e+04  170525.864807    0.0       0.00000   \n",
       "x282  100000.0  8.658500e-01       0.340815    0.0       1.00000   \n",
       "x283  100000.0  8.738400e-01       0.332031    0.0       1.00000   \n",
       "x284  100000.0  8.841400e-01       0.320059    0.0       1.00000   \n",
       "x285  100000.0  1.391490e+00       2.682935    0.0       0.00000   \n",
       "x286  100000.0  1.152600e-01       0.695126    0.0       0.00000   \n",
       "x287   75179.0  3.239309e+00       3.090414    1.0       1.00000   \n",
       "x288   50244.0  5.169799e+01      52.700032    0.0      14.00000   \n",
       "x289   50244.0  2.544553e+01      34.674418    0.0       5.00000   \n",
       "x290   50244.0  3.833166e+01      38.882567    0.0      11.66660   \n",
       "x291  100000.0  1.461510e+04   37717.143370    0.0       0.00000   \n",
       "x292  100000.0  5.839332e+04  164530.463427    0.0       0.00000   \n",
       "x293   48867.0  8.125753e-01       0.321268    0.0       0.64060   \n",
       "x294  100000.0  2.795508e+03   17515.777542    0.0       0.00000   \n",
       "x295   13467.0  9.013038e-01       0.433850    0.0       0.65635   \n",
       "x296  100000.0  1.181960e+04   32264.688940    0.0       0.00000   \n",
       "x297   41888.0  7.940343e-01       0.288249    0.0       0.63690   \n",
       "x298  100000.0  5.433200e-01       0.498122    0.0       0.00000   \n",
       "x299  100000.0  5.580300e-01       0.496624    0.0       0.00000   \n",
       "x300  100000.0  5.818300e-01       0.493261    0.0       0.00000   \n",
       "x301  100000.0  1.062400e-01       0.308146    0.0       0.00000   \n",
       "x302   26931.0  2.948758e+00       2.129430    1.0       1.00000   \n",
       "x303  100000.0  6.410883e+03   24190.243313    0.0       0.00000   \n",
       "x304   18125.0  1.037957e+00       0.330580    0.0       0.97580   \n",
       "y      80000.0  6.193978e+02     118.357217  300.0     524.00000   \n",
       "\n",
       "               50%           75%           max  \n",
       "x001  1.235926e+06  1.445326e+06  1.677197e+06  \n",
       "x002  1.000000e+02  1.800000e+02  7.180000e+02  \n",
       "x003  8.000000e+00  2.400000e+01  7.040000e+02  \n",
       "x004  4.800000e+01  9.200000e+01  7.040000e+02  \n",
       "x005  1.500000e+02  2.460000e+02  8.270000e+02  \n",
       "x006  0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x007  0.000000e+00  1.000000e+00  4.400000e+01  \n",
       "x008  1.000000e+00  2.000000e+00  1.080000e+02  \n",
       "x009  0.000000e+00  2.000000e+00  8.100000e+01  \n",
       "x010  0.000000e+00  1.000000e+00  3.300000e+01  \n",
       "x011  1.000000e+00  3.000000e+00  4.400000e+01  \n",
       "x012  1.000000e+00  2.000000e+00  4.400000e+01  \n",
       "x013  0.000000e+00  2.000000e+00  4.200000e+01  \n",
       "x014  2.000000e+00  7.000000e+00  6.800000e+01  \n",
       "x015  1.000000e+01  1.900000e+01  1.890000e+02  \n",
       "x016  3.000000e+00  6.000000e+00  8.700000e+01  \n",
       "x017  6.000000e+00  1.300000e+01  1.620000e+02  \n",
       "x018  4.000000e+00  6.000000e+00  1.600000e+01  \n",
       "x019  2.000000e+00  3.000000e+00  1.100000e+01  \n",
       "x020  4.000000e+00  1.000000e+01  1.590000e+02  \n",
       "x021  1.000000e+00  3.000000e+00  8.400000e+01  \n",
       "x022  2.000000e+00  3.000000e+00  6.000000e+00  \n",
       "x023  1.000000e+00  2.000000e+00  5.000000e+00  \n",
       "x024  2.000000e+00  6.000000e+00  1.290000e+02  \n",
       "x025  0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x026  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x027  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x028  0.000000e+00  1.000000e+00  4.700000e+01  \n",
       "x029  1.000000e+00  2.000000e+00  4.600000e+01  \n",
       "x030  3.000000e+00  6.000000e+00  1.340000e+02  \n",
       "...            ...           ...           ...  \n",
       "x276  0.000000e+00  0.000000e+00  2.900000e+01  \n",
       "x277  0.000000e+00  0.000000e+00  2.900000e+01  \n",
       "x278  0.000000e+00  0.000000e+00  3.200000e+01  \n",
       "x279  9.695000e+03  5.381500e+04  1.522472e+07  \n",
       "x280  0.000000e+00  1.820000e+02  4.087029e+06  \n",
       "x281  4.253000e+03  3.570575e+04  1.522406e+07  \n",
       "x282  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x283  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x284  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x285  1.000000e+00  2.000000e+00  4.100000e+01  \n",
       "x286  0.000000e+00  0.000000e+00  2.700000e+01  \n",
       "x287  1.000000e+00  5.000000e+00  9.000000e+00  \n",
       "x288  3.200000e+01  7.400000e+01  5.290000e+02  \n",
       "x289  1.400000e+01  3.100000e+01  4.650000e+02  \n",
       "x290  2.600000e+01  5.200000e+01  4.650000e+02  \n",
       "x291  0.000000e+00  1.712800e+04  4.348891e+06  \n",
       "x292  4.758000e+03  4.333125e+04  1.520793e+07  \n",
       "x293  8.601000e-01  9.970000e-01  1.839990e+01  \n",
       "x294  0.000000e+00  0.000000e+00  3.721366e+06  \n",
       "x295  9.406000e-01  1.140950e+00  1.839990e+01  \n",
       "x296  0.000000e+00  1.295600e+04  2.696702e+06  \n",
       "x297  8.510000e-01  9.820000e-01  1.303530e+01  \n",
       "x298  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x299  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x300  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "x301  0.000000e+00  0.000000e+00  1.000000e+00  \n",
       "x302  1.000000e+00  5.000000e+00  9.000000e+00  \n",
       "x303  0.000000e+00  0.000000e+00  7.855370e+05  \n",
       "x304  1.048600e+00  1.186200e+00  5.156900e+00  \n",
       "y     5.990000e+02  7.190000e+02  8.390000e+02  \n",
       "\n",
       "[305 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source        0\n",
       "x001          0\n",
       "x002      21432\n",
       "x003      21432\n",
       "x004      21424\n",
       "x005       6110\n",
       "x006          0\n",
       "x007          0\n",
       "x008          0\n",
       "x009          0\n",
       "x010          0\n",
       "x011          0\n",
       "x012          0\n",
       "x013          0\n",
       "x014          0\n",
       "x015          0\n",
       "x016          0\n",
       "x017          0\n",
       "x018          0\n",
       "x019          0\n",
       "x020          0\n",
       "x021          0\n",
       "x022          0\n",
       "x023          0\n",
       "x024          0\n",
       "x025          0\n",
       "x026          0\n",
       "x027          0\n",
       "x028          0\n",
       "x029          0\n",
       "          ...  \n",
       "x276          0\n",
       "x277          0\n",
       "x278          0\n",
       "x279          0\n",
       "x280          0\n",
       "x281          0\n",
       "x282          0\n",
       "x283          0\n",
       "x284          0\n",
       "x285          0\n",
       "x286          0\n",
       "x287      24821\n",
       "x288      49756\n",
       "x289      49756\n",
       "x290      49756\n",
       "x291          0\n",
       "x292          0\n",
       "x293      51133\n",
       "x294          0\n",
       "x295      86533\n",
       "x296          0\n",
       "x297      58112\n",
       "x298          0\n",
       "x299          0\n",
       "x300          0\n",
       "x301          0\n",
       "x302      73069\n",
       "x303          0\n",
       "x304      81875\n",
       "y         20000\n",
       "Length: 306, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([426., 160., 163.,  nan,   3., 112., 343., 175.,  53.,  10., 152.,\n",
       "       146.,  12., 330., 357., 203., 353., 360., 159., 245.,  40.,  24.,\n",
       "         8., 180., 293.,  22.,  75.,  27., 205.,  26.,  62., 128.,  16.,\n",
       "       254., 125., 188.,  60.,   0.,  42.,  14., 186.,   4.,  37.,   9.,\n",
       "       168.,  15., 248.,  21.,  86.,  94., 281.,   6., 144.,  32., 356.,\n",
       "        50., 149., 236., 126., 364., 170., 139., 169., 136., 204., 174.,\n",
       "       109.,   2.,  88.,  11., 240.,  82., 158., 201.,  20., 187., 626.,\n",
       "        49.,  41.,  61.,  77.,   7.,  96., 208., 235., 222.,  39.,  19.,\n",
       "       166.,  48.,   5., 111.,  97., 388.,  74., 227.,  30., 362.,  92.,\n",
       "        98.,  64., 577.,  29., 305., 130., 233., 107., 274.,  66., 289.,\n",
       "        59.,  18., 142.,  47., 304., 196., 247., 108., 212., 172., 239.,\n",
       "       114.,  78., 255.,  84.,  79.,  63.,  91.,  36.,  38., 104.,  17.,\n",
       "       154.,  31., 493.,  25., 327.,  43.,  55.,  46., 191., 478.,  28.,\n",
       "       347., 238., 634., 427., 256., 182., 277., 161., 217., 133., 119.,\n",
       "       284., 213., 135., 262.,  99., 298., 268.,  51.,  85., 218.,  54.,\n",
       "       123., 122., 153., 276., 207., 117., 110., 100., 253., 320., 307.,\n",
       "       124.,  72., 336.,  45., 179.,  90.,  33., 374., 129., 176.,  81.,\n",
       "        58., 461., 156., 350., 195.,  34., 138.,  23., 335., 430.,  56.,\n",
       "       113., 185., 121.,  65., 178., 371., 515., 331.,  68., 115., 296.,\n",
       "       243.,  13., 506., 219., 105., 181., 140., 514., 328., 127., 517.,\n",
       "       311., 417., 257., 199., 326., 173., 137., 321., 355., 118., 194.,\n",
       "       230., 120.,  71., 441.,   1.,  35., 215., 164., 318., 167., 270.,\n",
       "        83., 300., 102., 375., 216., 260., 165., 261., 608., 147., 143.,\n",
       "       177., 316.,  76., 342.,  93., 171., 234.,  67., 309., 465., 223.,\n",
       "       349., 391., 106., 337., 211., 323., 190., 103., 609., 116., 220.,\n",
       "       551., 479., 189., 591., 141.,  95.,  44., 193., 183., 265., 572.,\n",
       "       313.,  89., 278., 485., 134., 200., 249., 246., 228., 384., 148.,\n",
       "       412., 299., 206., 155., 145., 272., 131.,  87., 192., 452.,  57.,\n",
       "        52., 267.,  80., 198., 484., 361., 275., 226., 132., 366.,  69.,\n",
       "        70., 282., 242., 279., 363., 314., 424., 291., 150., 593., 297.,\n",
       "       370., 377., 341., 531., 306., 401., 280., 383., 162., 210., 157.,\n",
       "        73., 232., 379., 317., 237., 209., 294., 334., 527., 266., 288.,\n",
       "       214., 405., 184., 264., 406., 151., 410., 390., 287., 553., 197.,\n",
       "       290., 428., 269., 229., 400., 381., 516., 468., 365., 252., 332.,\n",
       "       482., 354., 303., 589., 338., 101., 292., 241., 486., 271., 224.,\n",
       "       244., 345., 359., 312., 202., 534., 552., 310., 392., 225., 554.,\n",
       "       324., 463., 471., 346., 475., 407., 614., 415., 231., 250., 329.,\n",
       "       378., 504., 568., 368., 301., 398., 380., 295., 436., 440., 369.,\n",
       "       263., 433., 385., 221., 449., 457., 285., 283., 325., 510., 387.,\n",
       "       333., 389., 418., 421., 397., 376., 550., 454., 403., 578., 273.,\n",
       "       259., 480., 251., 472., 557., 322., 394., 352., 372., 511., 319.,\n",
       "       435., 315., 458., 598., 437., 503., 466., 302., 367., 399., 308.,\n",
       "       469., 532., 456., 592., 429., 386., 348., 537., 344., 431., 393.,\n",
       "       459., 439., 339., 402., 442., 487., 382., 617., 473., 535., 340.,\n",
       "       446., 477., 258., 411., 450., 470., 521., 420., 414., 560., 358.,\n",
       "       621., 494., 512., 448., 564., 570., 438., 597., 460., 588., 373.,\n",
       "       286., 522., 529., 490., 507., 501., 455., 583., 704., 670., 528.,\n",
       "       495., 416., 423., 713., 422., 396., 488., 447., 444., 395., 491.,\n",
       "       612., 545., 546., 451., 513., 351., 576., 518., 462., 502., 508.,\n",
       "       434., 574., 536., 489., 540., 404., 524., 605., 464., 413., 500.,\n",
       "       497., 549., 559., 408., 509., 571., 419., 409., 505., 544., 646.,\n",
       "       453., 526., 445., 492., 595., 525., 425., 476., 580., 573., 543.,\n",
       "       555., 542., 575., 483., 538., 623., 541., 569., 519., 601., 548.,\n",
       "       599., 496., 432., 523., 520., 643., 499., 692., 585., 467., 539.,\n",
       "       443., 563., 616., 606., 556., 533., 498., 481., 600., 610., 474.,\n",
       "       565., 682., 581., 562., 636., 566., 604., 658., 590., 653., 650.,\n",
       "       607., 587., 630., 637., 567., 648., 624., 530., 603., 640., 579.,\n",
       "       586., 602., 596., 680., 584., 700., 641., 632., 647., 582., 611.,\n",
       "       633., 691., 620., 649., 558., 718., 561., 547., 710., 694., 615.,\n",
       "       613., 665., 635., 628., 671., 657., 695., 619., 679., 629., 696.,\n",
       "       627., 622., 644., 625., 666., 693., 594.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.x002.unique()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.x002.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source        0\n",
       "x001          0\n",
       "x002      21432\n",
       "x003      21432\n",
       "x004      21424\n",
       "x005       6110\n",
       "x006          0\n",
       "x007          0\n",
       "x008          0\n",
       "x009          0\n",
       "x010          0\n",
       "x011          0\n",
       "x012          0\n",
       "x013          0\n",
       "x014          0\n",
       "x015          0\n",
       "x016          0\n",
       "x017          0\n",
       "x018          0\n",
       "x019          0\n",
       "x020          0\n",
       "x021          0\n",
       "x022          0\n",
       "x023          0\n",
       "x024          0\n",
       "x025          0\n",
       "x026          0\n",
       "x027          0\n",
       "x028          0\n",
       "x029          0\n",
       "          ...  \n",
       "x276          0\n",
       "x277          0\n",
       "x278          0\n",
       "x279          0\n",
       "x280          0\n",
       "x281          0\n",
       "x282          0\n",
       "x283          0\n",
       "x284          0\n",
       "x285          0\n",
       "x286          0\n",
       "x287      24821\n",
       "x288      49756\n",
       "x289      49756\n",
       "x290      49756\n",
       "x291          0\n",
       "x292          0\n",
       "x293      51133\n",
       "x294          0\n",
       "x295      86533\n",
       "x296          0\n",
       "x297      58112\n",
       "x298          0\n",
       "x299          0\n",
       "x300          0\n",
       "x301          0\n",
       "x302      73069\n",
       "x303          0\n",
       "x304      81875\n",
       "y         20000\n",
       "Length: 306, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x242</th>\n",
       "      <td>x242</td>\n",
       "      <td>93.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x295</th>\n",
       "      <td>x295</td>\n",
       "      <td>86.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x304</th>\n",
       "      <td>x304</td>\n",
       "      <td>81.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x098</th>\n",
       "      <td>x098</td>\n",
       "      <td>80.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x155</th>\n",
       "      <td>x155</td>\n",
       "      <td>79.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x259</th>\n",
       "      <td>x259</td>\n",
       "      <td>77.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x256</th>\n",
       "      <td>x256</td>\n",
       "      <td>76.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x255</th>\n",
       "      <td>x255</td>\n",
       "      <td>76.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x257</th>\n",
       "      <td>x257</td>\n",
       "      <td>76.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x302</th>\n",
       "      <td>x302</td>\n",
       "      <td>73.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x268</th>\n",
       "      <td>x268</td>\n",
       "      <td>67.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x162</th>\n",
       "      <td>x162</td>\n",
       "      <td>66.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x266</th>\n",
       "      <td>x266</td>\n",
       "      <td>66.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x267</th>\n",
       "      <td>x267</td>\n",
       "      <td>66.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x265</th>\n",
       "      <td>x265</td>\n",
       "      <td>66.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x253</th>\n",
       "      <td>x253</td>\n",
       "      <td>66.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x297</th>\n",
       "      <td>x297</td>\n",
       "      <td>58.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x275</th>\n",
       "      <td>x275</td>\n",
       "      <td>56.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x293</th>\n",
       "      <td>x293</td>\n",
       "      <td>51.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x288</th>\n",
       "      <td>x288</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x290</th>\n",
       "      <td>x290</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x289</th>\n",
       "      <td>x289</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x148</th>\n",
       "      <td>x148</td>\n",
       "      <td>41.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x223</th>\n",
       "      <td>x223</td>\n",
       "      <td>37.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x222</th>\n",
       "      <td>x222</td>\n",
       "      <td>36.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x058</th>\n",
       "      <td>x058</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x057</th>\n",
       "      <td>x057</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x041</th>\n",
       "      <td>x041</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x237</th>\n",
       "      <td>x237</td>\n",
       "      <td>36.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x239</th>\n",
       "      <td>x239</td>\n",
       "      <td>36.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x095</th>\n",
       "      <td>x095</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x094</th>\n",
       "      <td>x094</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x093</th>\n",
       "      <td>x093</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x091</th>\n",
       "      <td>x091</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x101</th>\n",
       "      <td>x101</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x090</th>\n",
       "      <td>x090</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x089</th>\n",
       "      <td>x089</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x088</th>\n",
       "      <td>x088</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x087</th>\n",
       "      <td>x087</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x086</th>\n",
       "      <td>x086</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x085</th>\n",
       "      <td>x085</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x100</th>\n",
       "      <td>x100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x102</th>\n",
       "      <td>x102</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x118</th>\n",
       "      <td>x118</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x111</th>\n",
       "      <td>x111</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x117</th>\n",
       "      <td>x117</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x116</th>\n",
       "      <td>x116</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x115</th>\n",
       "      <td>x115</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x114</th>\n",
       "      <td>x114</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x113</th>\n",
       "      <td>x113</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x112</th>\n",
       "      <td>x112</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x110</th>\n",
       "      <td>x110</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x103</th>\n",
       "      <td>x103</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x109</th>\n",
       "      <td>x109</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x108</th>\n",
       "      <td>x108</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x107</th>\n",
       "      <td>x107</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x106</th>\n",
       "      <td>x106</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x105</th>\n",
       "      <td>x105</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x104</th>\n",
       "      <td>x104</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x153</th>\n",
       "      <td>x153</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name  percent_missing\n",
       "x242        x242           93.339\n",
       "x295        x295           86.533\n",
       "x304        x304           81.875\n",
       "x098        x098           80.681\n",
       "x155        x155           79.051\n",
       "x259        x259           77.432\n",
       "x256        x256           76.913\n",
       "x255        x255           76.913\n",
       "x257        x257           76.913\n",
       "x302        x302           73.069\n",
       "x268        x268           67.253\n",
       "x162        x162           66.481\n",
       "x266        x266           66.461\n",
       "x267        x267           66.461\n",
       "x265        x265           66.461\n",
       "x253        x253           66.333\n",
       "x297        x297           58.112\n",
       "x275        x275           56.131\n",
       "x293        x293           51.133\n",
       "x288        x288           49.756\n",
       "x290        x290           49.756\n",
       "x289        x289           49.756\n",
       "x148        x148           41.785\n",
       "x223        x223           37.069\n",
       "x222        x222           36.987\n",
       "x058        x058           36.872\n",
       "x057        x057           36.872\n",
       "x041        x041           36.872\n",
       "x237        x237           36.744\n",
       "x239        x239           36.744\n",
       "...          ...              ...\n",
       "x095        x095            0.000\n",
       "x094        x094            0.000\n",
       "x093        x093            0.000\n",
       "x091        x091            0.000\n",
       "x101        x101            0.000\n",
       "x090        x090            0.000\n",
       "x089        x089            0.000\n",
       "x088        x088            0.000\n",
       "x087        x087            0.000\n",
       "x086        x086            0.000\n",
       "x085        x085            0.000\n",
       "x100        x100            0.000\n",
       "x102        x102            0.000\n",
       "x118        x118            0.000\n",
       "x111        x111            0.000\n",
       "x117        x117            0.000\n",
       "x116        x116            0.000\n",
       "x115        x115            0.000\n",
       "x114        x114            0.000\n",
       "x113        x113            0.000\n",
       "x112        x112            0.000\n",
       "x110        x110            0.000\n",
       "x103        x103            0.000\n",
       "x109        x109            0.000\n",
       "x108        x108            0.000\n",
       "x107        x107            0.000\n",
       "x106        x106            0.000\n",
       "x105        x105            0.000\n",
       "x104        x104            0.000\n",
       "x153        x153            0.000\n",
       "\n",
       "[306 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_df.sort_values('percent_missing',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh=df.shape[0]*0.5,how='all',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 287)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with their distinct count and their classification\n",
      "source == 2 == disc\n",
      "x001 == 100000 == cont\n",
      "x002 == 666 == cont\n",
      "x003 == 457 == cont\n",
      "x004 == 492 == cont\n",
      "x005 == 699 == cont\n",
      "x006 == 2 == disc\n",
      "x007 == 32 == medium\n",
      "x008 == 44 == medium\n",
      "x009 == 42 == medium\n",
      "x010 == 30 == medium\n",
      "x011 == 41 == medium\n",
      "x012 == 38 == medium\n",
      "x013 == 39 == medium\n",
      "x014 == 60 == medium\n",
      "x015 == 125 == cont\n",
      "x016 == 58 == medium\n",
      "x017 == 110 == cont\n",
      "x018 == 17 == medium\n",
      "x019 == 12 == medium\n",
      "x020 == 95 == medium\n",
      "x021 == 49 == medium\n",
      "x022 == 7 == disc\n",
      "x023 == 6 == disc\n",
      "x024 == 106 == cont\n",
      "x025 == 2 == disc\n",
      "x026 == 2 == disc\n",
      "x027 == 2 == disc\n",
      "x028 == 30 == medium\n",
      "x029 == 30 == medium\n",
      "x030 == 69 == medium\n",
      "x031 == 122 == cont\n",
      "x032 == 27 == medium\n",
      "x033 == 41 == medium\n",
      "x034 == 59 == medium\n",
      "x035 == 84 == medium\n",
      "x036 == 41 == medium\n",
      "x037 == 5 == disc\n",
      "x038 == 12 == medium\n",
      "x039 == 18 == medium\n",
      "x040 == 28 == medium\n",
      "x041 == 12056 == cont\n",
      "x042 == 8728 == cont\n",
      "x043 == 28977 == cont\n",
      "x044 == 4384 == cont\n",
      "x045 == 1262 == cont\n",
      "x046 == 19 == medium\n",
      "x047 == 11 == medium\n",
      "x048 == 11 == medium\n",
      "x049 == 9 == disc\n",
      "x050 == 8 == disc\n",
      "x051 == 8 == disc\n",
      "x052 == 8 == disc\n",
      "x053 == 9 == disc\n",
      "x054 == 11 == medium\n",
      "x055 == 17 == medium\n",
      "x056 == 24 == medium\n",
      "x057 == 11839 == cont\n",
      "x058 == 8574 == cont\n",
      "x059 == 95 == medium\n",
      "x060 == 2 == disc\n",
      "x061 == 16 == medium\n",
      "x062 == 29 == medium\n",
      "x063 == 44 == medium\n",
      "x064 == 67 == medium\n",
      "x065 == 90 == medium\n",
      "x066 == 34 == medium\n",
      "x067 == 1 == disc\n",
      "x068 == 7 == disc\n",
      "x069 == 15 == medium\n",
      "x070 == 21 == medium\n",
      "x071 == 29 == medium\n",
      "x072 == 31 == medium\n",
      "x073 == 97 == medium\n",
      "x074 == 34 == medium\n",
      "x075 == 11941 == cont\n",
      "x076 == 30 == medium\n",
      "x077 == 4 == disc\n",
      "x078 == 6 == disc\n",
      "x079 == 9 == disc\n",
      "x080 == 18 == medium\n",
      "x081 == 25 == medium\n",
      "x082 == 2 == disc\n",
      "x083 == 2 == disc\n",
      "x084 == 2 == disc\n",
      "x085 == 2 == disc\n",
      "x086 == 2 == disc\n",
      "x087 == 2 == disc\n",
      "x088 == 2 == disc\n",
      "x089 == 2 == disc\n",
      "x090 == 2 == disc\n",
      "x091 == 2 == disc\n",
      "x092 == 2 == disc\n",
      "x093 == 2 == disc\n",
      "x094 == 1 == disc\n",
      "x095 == 1 == disc\n",
      "x096 == 1 == disc\n",
      "x097 == 23 == medium\n",
      "x099 == 26 == medium\n",
      "x100 == 13 == medium\n",
      "x101 == 13 == medium\n",
      "x102 == 19 == medium\n",
      "x103 == 24 == medium\n",
      "x104 == 25 == medium\n",
      "x105 == 25 == medium\n",
      "x106 == 30 == medium\n",
      "x107 == 10 == disc\n",
      "x108 == 14 == medium\n",
      "x109 == 22 == medium\n",
      "x110 == 29 == medium\n",
      "x111 == 194 == cont\n",
      "x112 == 17 == medium\n",
      "x113 == 25 == medium\n",
      "x114 == 40 == medium\n",
      "x115 == 49 == medium\n",
      "x116 == 60 == medium\n",
      "x117 == 69 == medium\n",
      "x118 == 99 == medium\n",
      "x119 == 139 == cont\n",
      "x120 == 168 == cont\n",
      "x121 == 193 == cont\n",
      "x122 == 16 == medium\n",
      "x123 == 19 == medium\n",
      "x124 == 26 == medium\n",
      "x125 == 35 == medium\n",
      "x126 == 45 == medium\n",
      "x127 == 65 == medium\n",
      "x128 == 97 == medium\n",
      "x129 == 131 == cont\n",
      "x130 == 164 == cont\n",
      "x131 == 186 == cont\n",
      "x132 == 24 == medium\n",
      "x133 == 32 == medium\n",
      "x134 == 49 == medium\n",
      "x135 == 56 == medium\n",
      "x136 == 65 == medium\n",
      "x137 == 63 == medium\n",
      "x138 == 96 == medium\n",
      "x139 == 131 == cont\n",
      "x140 == 158 == cont\n",
      "x141 == 181 == cont\n",
      "x142 == 56 == medium\n",
      "x143 == 82 == medium\n",
      "x144 == 110 == cont\n",
      "x145 == 138 == cont\n",
      "x146 == 154 == cont\n",
      "x147 == 2 == disc\n",
      "x148 == 7 == disc\n",
      "x149 == 20 == medium\n",
      "x150 == 23 == medium\n",
      "x151 == 33 == medium\n",
      "x152 == 37 == medium\n",
      "x153 == 41 == medium\n",
      "x154 == 2 == disc\n",
      "x156 == 10 == disc\n",
      "x157 == 21 == medium\n",
      "x158 == 44 == medium\n",
      "x159 == 55 == medium\n",
      "x160 == 69 == medium\n",
      "x161 == 2 == disc\n",
      "x163 == 11 == medium\n",
      "x164 == 22 == medium\n",
      "x165 == 39 == medium\n",
      "x166 == 45 == medium\n",
      "x167 == 54 == medium\n",
      "x168 == 28 == medium\n",
      "x169 == 19 == medium\n",
      "x170 == 24 == medium\n",
      "x171 == 26 == medium\n",
      "x172 == 26 == medium\n",
      "x173 == 27 == medium\n",
      "x174 == 19 == medium\n",
      "x175 == 12 == medium\n",
      "x176 == 14 == medium\n",
      "x177 == 17 == medium\n",
      "x178 == 18 == medium\n",
      "x179 == 18 == medium\n",
      "x180 == 2 == disc\n",
      "x181 == 43 == medium\n",
      "x182 == 15 == medium\n",
      "x183 == 18 == medium\n",
      "x184 == 25 == medium\n",
      "x185 == 39 == medium\n",
      "x186 == 270 == cont\n",
      "x187 == 26 == medium\n",
      "x188 == 35 == medium\n",
      "x189 == 47 == medium\n",
      "x190 == 59 == medium\n",
      "x191 == 69 == medium\n",
      "x192 == 75 == medium\n",
      "x193 == 117 == cont\n",
      "x194 == 170 == cont\n",
      "x195 == 207 == cont\n",
      "x196 == 238 == cont\n",
      "x197 == 20 == medium\n",
      "x198 == 25 == medium\n",
      "x199 == 31 == medium\n",
      "x200 == 42 == medium\n",
      "x201 == 47 == medium\n",
      "x202 == 68 == medium\n",
      "x203 == 112 == cont\n",
      "x204 == 164 == cont\n",
      "x205 == 202 == cont\n",
      "x206 == 234 == cont\n",
      "x207 == 25 == medium\n",
      "x208 == 33 == medium\n",
      "x209 == 48 == medium\n",
      "x210 == 60 == medium\n",
      "x211 == 69 == medium\n",
      "x212 == 67 == medium\n",
      "x213 == 109 == cont\n",
      "x214 == 166 == cont\n",
      "x215 == 196 == cont\n",
      "x216 == 225 == cont\n",
      "x217 == 59 == medium\n",
      "x218 == 97 == medium\n",
      "x219 == 142 == cont\n",
      "x220 == 174 == cont\n",
      "x221 == 204 == cont\n",
      "x222 == 171 == cont\n",
      "x223 == 172 == cont\n",
      "x224 == 33 == medium\n",
      "x225 == 26 == medium\n",
      "x226 == 23 == medium\n",
      "x227 == 21 == medium\n",
      "x228 == 13 == medium\n",
      "x229 == 11 == medium\n",
      "x230 == 20 == medium\n",
      "x231 == 32 == medium\n",
      "x232 == 44 == medium\n",
      "x233 == 19427 == cont\n",
      "x234 == 13800 == cont\n",
      "x235 == 2947 == cont\n",
      "x236 == 27954 == cont\n",
      "x237 == 665 == cont\n",
      "x238 == 517 == cont\n",
      "x239 == 7179 == cont\n",
      "x240 == 36 == medium\n",
      "x241 == 18 == medium\n",
      "x243 == 2832 == cont\n",
      "x244 == 2 == disc\n",
      "x245 == 2 == disc\n",
      "x246 == 2 == disc\n",
      "x247 == 2 == disc\n",
      "x248 == 2 == disc\n",
      "x249 == 2 == disc\n",
      "x250 == 34 == medium\n",
      "x251 == 15 == medium\n",
      "x252 == 4 == disc\n",
      "x254 == 15 == medium\n",
      "x258 == 20810 == cont\n",
      "x260 == 2 == disc\n",
      "x261 == 2 == disc\n",
      "x262 == 2 == disc\n",
      "x263 == 2 == disc\n",
      "x264 == 21708 == cont\n",
      "x269 == 2 == disc\n",
      "x270 == 2 == disc\n",
      "x271 == 2 == disc\n",
      "x272 == 13374 == cont\n",
      "x273 == 52200 == cont\n",
      "x274 == 15222 == cont\n",
      "x276 == 26 == medium\n",
      "x277 == 27 == medium\n",
      "x278 == 30 == medium\n",
      "x279 == 49169 == cont\n",
      "x280 == 16477 == cont\n",
      "x281 == 43424 == cont\n",
      "x282 == 2 == disc\n",
      "x283 == 2 == disc\n",
      "x284 == 2 == disc\n",
      "x285 == 40 == medium\n",
      "x286 == 25 == medium\n",
      "x287 == 8 == disc\n",
      "x288 == 368 == cont\n",
      "x289 == 304 == cont\n",
      "x290 == 4086 == cont\n",
      "x291 == 32364 == cont\n",
      "x292 == 43857 == cont\n",
      "x294 == 10939 == cont\n",
      "x296 == 28477 == cont\n",
      "x298 == 2 == disc\n",
      "x299 == 2 == disc\n",
      "x300 == 2 == disc\n",
      "x301 == 2 == disc\n",
      "x303 == 15165 == cont\n",
      "y == 539 == cont\n"
     ]
    }
   ],
   "source": [
    "# Identify discrete and continous columns\n",
    "col_disc=[]\n",
    "col_medium=[]\n",
    "col_cont=[]\n",
    "print(\"Attributes with their distinct count and their classification\")\n",
    "for i in df.columns:\n",
    "    if df[i].nunique() <=10:\n",
    "        print(i,\"==\",df[i].nunique(),\"== disc\")\n",
    "        col_disc.append(i)\n",
    "    elif (df[i].nunique() >10 and df[i].nunique() <100):\n",
    "        col_medium.append(i)    \n",
    "        print(i,\"==\",df[i].nunique(),\"== medium\")\n",
    "    else:\n",
    "        col_cont.append(i)\n",
    "        print(i,\"==\",df[i].nunique(),\"== cont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x289</th>\n",
       "      <td>x289</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x288</th>\n",
       "      <td>x288</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x290</th>\n",
       "      <td>x290</td>\n",
       "      <td>49.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x148</th>\n",
       "      <td>x148</td>\n",
       "      <td>41.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x223</th>\n",
       "      <td>x223</td>\n",
       "      <td>37.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x222</th>\n",
       "      <td>x222</td>\n",
       "      <td>36.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x058</th>\n",
       "      <td>x058</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x057</th>\n",
       "      <td>x057</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x041</th>\n",
       "      <td>x041</td>\n",
       "      <td>36.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x238</th>\n",
       "      <td>x238</td>\n",
       "      <td>36.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x239</th>\n",
       "      <td>x239</td>\n",
       "      <td>36.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x237</th>\n",
       "      <td>x237</td>\n",
       "      <td>36.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x287</th>\n",
       "      <td>x287</td>\n",
       "      <td>24.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x003</th>\n",
       "      <td>x003</td>\n",
       "      <td>21.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x002</th>\n",
       "      <td>x002</td>\n",
       "      <td>21.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x004</th>\n",
       "      <td>x004</td>\n",
       "      <td>21.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x235</th>\n",
       "      <td>x235</td>\n",
       "      <td>20.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>y</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x045</th>\n",
       "      <td>x045</td>\n",
       "      <td>19.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x044</th>\n",
       "      <td>x044</td>\n",
       "      <td>19.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x234</th>\n",
       "      <td>x234</td>\n",
       "      <td>19.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x272</th>\n",
       "      <td>x272</td>\n",
       "      <td>7.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x005</th>\n",
       "      <td>x005</td>\n",
       "      <td>6.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x194</th>\n",
       "      <td>x194</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x193</th>\n",
       "      <td>x193</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x192</th>\n",
       "      <td>x192</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x191</th>\n",
       "      <td>x191</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x291</th>\n",
       "      <td>x291</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x196</th>\n",
       "      <td>x196</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x190</th>\n",
       "      <td>x190</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x082</th>\n",
       "      <td>x082</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x083</th>\n",
       "      <td>x083</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x084</th>\n",
       "      <td>x084</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x085</th>\n",
       "      <td>x085</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x086</th>\n",
       "      <td>x086</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x087</th>\n",
       "      <td>x087</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x088</th>\n",
       "      <td>x088</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x089</th>\n",
       "      <td>x089</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x090</th>\n",
       "      <td>x090</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x091</th>\n",
       "      <td>x091</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x092</th>\n",
       "      <td>x092</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x093</th>\n",
       "      <td>x093</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x094</th>\n",
       "      <td>x094</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x096</th>\n",
       "      <td>x096</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x112</th>\n",
       "      <td>x112</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x097</th>\n",
       "      <td>x097</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x099</th>\n",
       "      <td>x099</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x100</th>\n",
       "      <td>x100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x101</th>\n",
       "      <td>x101</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x102</th>\n",
       "      <td>x102</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x103</th>\n",
       "      <td>x103</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x104</th>\n",
       "      <td>x104</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x105</th>\n",
       "      <td>x105</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x106</th>\n",
       "      <td>x106</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x107</th>\n",
       "      <td>x107</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x108</th>\n",
       "      <td>x108</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x109</th>\n",
       "      <td>x109</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x110</th>\n",
       "      <td>x110</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x111</th>\n",
       "      <td>x111</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x144</th>\n",
       "      <td>x144</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name  percent_missing\n",
       "x289        x289           49.756\n",
       "x288        x288           49.756\n",
       "x290        x290           49.756\n",
       "x148        x148           41.785\n",
       "x223        x223           37.069\n",
       "x222        x222           36.987\n",
       "x058        x058           36.872\n",
       "x057        x057           36.872\n",
       "x041        x041           36.872\n",
       "x238        x238           36.744\n",
       "x239        x239           36.744\n",
       "x237        x237           36.744\n",
       "x287        x287           24.821\n",
       "x003        x003           21.432\n",
       "x002        x002           21.432\n",
       "x004        x004           21.424\n",
       "x235        x235           20.083\n",
       "y              y           20.000\n",
       "x045        x045           19.674\n",
       "x044        x044           19.674\n",
       "x234        x234           19.110\n",
       "x272        x272            7.189\n",
       "x005        x005            6.110\n",
       "x194        x194            0.000\n",
       "x193        x193            0.000\n",
       "x192        x192            0.000\n",
       "x191        x191            0.000\n",
       "x291        x291            0.000\n",
       "x196        x196            0.000\n",
       "x190        x190            0.000\n",
       "...          ...              ...\n",
       "x082        x082            0.000\n",
       "x083        x083            0.000\n",
       "x084        x084            0.000\n",
       "x085        x085            0.000\n",
       "x086        x086            0.000\n",
       "x087        x087            0.000\n",
       "x088        x088            0.000\n",
       "x089        x089            0.000\n",
       "x090        x090            0.000\n",
       "x091        x091            0.000\n",
       "x092        x092            0.000\n",
       "x093        x093            0.000\n",
       "x094        x094            0.000\n",
       "x096        x096            0.000\n",
       "x112        x112            0.000\n",
       "x097        x097            0.000\n",
       "x099        x099            0.000\n",
       "x100        x100            0.000\n",
       "x101        x101            0.000\n",
       "x102        x102            0.000\n",
       "x103        x103            0.000\n",
       "x104        x104            0.000\n",
       "x105        x105            0.000\n",
       "x106        x106            0.000\n",
       "x107        x107            0.000\n",
       "x108        x108            0.000\n",
       "x109        x109            0.000\n",
       "x110        x110            0.000\n",
       "x111        x111            0.000\n",
       "x144        x144            0.000\n",
       "\n",
       "[287 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x002', 'x003', 'x004', 'x005', 'x041', 'x044', 'x045', 'x057',\n",
       "       'x058', 'x148', 'x222', 'x223', 'x234', 'x235', 'x237', 'x238',\n",
       "       'x239', 'x272', 'x287', 'x288', 'x289', 'x290', 'y'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_na_lst=missing_value_df.loc[missing_value_df[\"percent_missing\"] >0,\"column_name\"].values\n",
    "col_na_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-af25d1988952>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-af25d1988952>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    col_na_lst1 =\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "col_na_lst1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x002 Continuous\n",
      "x003 Continuous\n",
      "x004 Continuous\n",
      "x005 Continuous\n",
      "x041 Continuous\n",
      "x044 Continuous\n",
      "x045 Continuous\n",
      "x057 Continuous\n",
      "x058 Continuous\n",
      "x148 Discrete\n",
      "x222 Continuous\n",
      "x223 Continuous\n",
      "x234 Continuous\n",
      "x235 Continuous\n",
      "x237 Continuous\n",
      "x238 Continuous\n",
      "x239 Continuous\n",
      "x272 Continuous\n",
      "x287 Discrete\n",
      "x288 Continuous\n",
      "x289 Continuous\n",
      "x290 Continuous\n",
      "do nothing\n"
     ]
    }
   ],
   "source": [
    "for i in col_na_lst:\n",
    "    if i == 'y':\n",
    "        print(\"do nothing\")\n",
    "    elif i in col_disc:\n",
    "        print(i,\"Discrete\")\n",
    "        df[i].fillna((df[i].mode()[0]), inplace=True)\n",
    "    else:\n",
    "        print(i,\"Continuous\")\n",
    "        df[i].fillna((df[i].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>y</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x192</th>\n",
       "      <td>x192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x198</th>\n",
       "      <td>x198</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x197</th>\n",
       "      <td>x197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x196</th>\n",
       "      <td>x196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x195</th>\n",
       "      <td>x195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x194</th>\n",
       "      <td>x194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x193</th>\n",
       "      <td>x193</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x191</th>\n",
       "      <td>x191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x200</th>\n",
       "      <td>x200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x190</th>\n",
       "      <td>x190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x189</th>\n",
       "      <td>x189</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x188</th>\n",
       "      <td>x188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x187</th>\n",
       "      <td>x187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x186</th>\n",
       "      <td>x186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x185</th>\n",
       "      <td>x185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x199</th>\n",
       "      <td>x199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x201</th>\n",
       "      <td>x201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x183</th>\n",
       "      <td>x183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x210</th>\n",
       "      <td>x210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x216</th>\n",
       "      <td>x216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x215</th>\n",
       "      <td>x215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x214</th>\n",
       "      <td>x214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x213</th>\n",
       "      <td>x213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x212</th>\n",
       "      <td>x212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x211</th>\n",
       "      <td>x211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x209</th>\n",
       "      <td>x209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x202</th>\n",
       "      <td>x202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x208</th>\n",
       "      <td>x208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x207</th>\n",
       "      <td>x207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x084</th>\n",
       "      <td>x084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x083</th>\n",
       "      <td>x083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x082</th>\n",
       "      <td>x082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x080</th>\n",
       "      <td>x080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x089</th>\n",
       "      <td>x089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x079</th>\n",
       "      <td>x079</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x078</th>\n",
       "      <td>x078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x077</th>\n",
       "      <td>x077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x076</th>\n",
       "      <td>x076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x075</th>\n",
       "      <td>x075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x074</th>\n",
       "      <td>x074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x088</th>\n",
       "      <td>x088</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x090</th>\n",
       "      <td>x090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x107</th>\n",
       "      <td>x107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x100</th>\n",
       "      <td>x100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x106</th>\n",
       "      <td>x106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x105</th>\n",
       "      <td>x105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x104</th>\n",
       "      <td>x104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x103</th>\n",
       "      <td>x103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x102</th>\n",
       "      <td>x102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x101</th>\n",
       "      <td>x101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x099</th>\n",
       "      <td>x099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x091</th>\n",
       "      <td>x091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x097</th>\n",
       "      <td>x097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x096</th>\n",
       "      <td>x096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x095</th>\n",
       "      <td>x095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x094</th>\n",
       "      <td>x094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x093</th>\n",
       "      <td>x093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x092</th>\n",
       "      <td>x092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x144</th>\n",
       "      <td>x144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     column_name  percent_missing\n",
       "y              y             20.0\n",
       "x192        x192              0.0\n",
       "x198        x198              0.0\n",
       "x197        x197              0.0\n",
       "x196        x196              0.0\n",
       "x195        x195              0.0\n",
       "x194        x194              0.0\n",
       "x193        x193              0.0\n",
       "x191        x191              0.0\n",
       "x200        x200              0.0\n",
       "x190        x190              0.0\n",
       "x189        x189              0.0\n",
       "x188        x188              0.0\n",
       "x187        x187              0.0\n",
       "x186        x186              0.0\n",
       "x185        x185              0.0\n",
       "x199        x199              0.0\n",
       "x201        x201              0.0\n",
       "x183        x183              0.0\n",
       "x210        x210              0.0\n",
       "x216        x216              0.0\n",
       "x215        x215              0.0\n",
       "x214        x214              0.0\n",
       "x213        x213              0.0\n",
       "x212        x212              0.0\n",
       "x211        x211              0.0\n",
       "x209        x209              0.0\n",
       "x202        x202              0.0\n",
       "x208        x208              0.0\n",
       "x207        x207              0.0\n",
       "...          ...              ...\n",
       "x084        x084              0.0\n",
       "x083        x083              0.0\n",
       "x082        x082              0.0\n",
       "x080        x080              0.0\n",
       "x089        x089              0.0\n",
       "x079        x079              0.0\n",
       "x078        x078              0.0\n",
       "x077        x077              0.0\n",
       "x076        x076              0.0\n",
       "x075        x075              0.0\n",
       "x074        x074              0.0\n",
       "x088        x088              0.0\n",
       "x090        x090              0.0\n",
       "x107        x107              0.0\n",
       "x100        x100              0.0\n",
       "x106        x106              0.0\n",
       "x105        x105              0.0\n",
       "x104        x104              0.0\n",
       "x103        x103              0.0\n",
       "x102        x102              0.0\n",
       "x101        x101              0.0\n",
       "x099        x099              0.0\n",
       "x091        x091              0.0\n",
       "x097        x097              0.0\n",
       "x096        x096              0.0\n",
       "x095        x095              0.0\n",
       "x094        x094              0.0\n",
       "x093        x093              0.0\n",
       "x092        x092              0.0\n",
       "x144        x144              0.0\n",
       "\n",
       "[287 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'x001', 'x002', 'x003', 'x004', 'x005', 'x006', 'x007',\n",
       "       'x008', 'x009',\n",
       "       ...\n",
       "       'x291', 'x292', 'x294', 'x296', 'x298', 'x299', 'x300', 'x301', 'x303',\n",
       "       'y'],\n",
       "      dtype='object', length=287)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = df[df.source==\"train\"]\n",
    "test_final = df[df.source==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_final.drop(columns=\"source\",inplace=True)\n",
    "test_final.drop(columns=\"source\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and data\n",
    "train_X = train_final.drop(columns=[\"y\"])\n",
    "train_Y = train_final[\"y\"]\n",
    "test_X = test_final.drop(columns=[\"y\"])\n",
    "test_Y = test_final[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_metrics={}\n",
    "def calc_metrics_and_predict(model,model_label,train_X,test_X,train_Y,test_Y,test_final, scaler,cv):\n",
    "    if scaler is not None:\n",
    "        # Scaling\n",
    "        print(\"Scaling applied\")\n",
    "        train_X = scaler.fit_transform(train_X)\n",
    "        test_X = scaler.transform(test_X)\n",
    "    print(\"fit data\")    \n",
    "    model.fit(train_X, train_Y)\n",
    "    print(\"predict data\")\n",
    "    yhat_train = model.predict(train_X)\n",
    "    rmse=np.sqrt(mean_squared_error(train_Y, yhat_train))\n",
    "    mae=mean_absolute_error(train_Y,yhat_train)\n",
    "    #mape=np.mean(np.abs((train_Y - yhat_train) / train_Y)) * 100\n",
    "    mape=mae * 100\n",
    "    if cv==True:\n",
    "        print(\"Cross-Validation score\")\n",
    "        scores = cross_val_score(model, train_X, train_Y, cv = 10,scoring='neg_mean_squared_error') \n",
    "        avg_cross_val_score = np.mean(np.sqrt(np.abs(scores)))\n",
    "    else:\n",
    "        avg_cross_val_score=None\n",
    "    #avg_cross_val_score=0\n",
    "    model_metrics[model_label]=[rmse,mae,mape,avg_cross_val_score]\n",
    "    # Predict test data and add to test_fnal dataframe\n",
    "    test_final[model_label] =  model.predict(test_X)\n",
    "    return model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                                max_depth=None,\n",
       "                                                max_features='auto',\n",
       "                                                max_leaf_nodes=None,\n",
       "                                                min_impurity_decrease=0.0,\n",
       "                                                min_impurity_split=None,\n",
       "                                                min_samples_leaf=1,\n",
       "                                                min_samples_split=2,\n",
       "                                                min_weight_fraction_leaf=0.0,\n",
       "                                                n_estimators=100, n_jobs=None,\n",
       "                                                oob_score=False,\n",
       "                                                random_state=None, verbose=0,\n",
       "                                                warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "sel = SelectFromModel(RandomForestRegressor(n_estimators = 100))\n",
    "sel.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat= train_X.columns[(sel.get_support())]\n",
    "len(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x005', 'x006', 'x014', 'x036', 'x041', 'x043', 'x044', 'x055', 'x057',\n",
       "       'x075', 'x099', 'x181', 'x234', 'x235', 'x236', 'x240', 'x245', 'x272',\n",
       "       'x274', 'x276', 'x281'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_feat = df[['x005', 'x006', 'x014', 'x036', 'x041', 'x043', 'x044', 'x055', 'x057',\n",
    "       'x075', 'x099', 'x181', 'x234', 'x235', 'x236', 'x240', 'x245', 'x272',\n",
    "       'x274', 'x276', 'x281','source','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sel_final = df_selected_feat[df_selected_feat.source==\"train\"]\n",
    "test_sel_final = df_selected_feat[df_selected_feat.source==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_sel_final.drop(columns=\"source\",inplace=True)\n",
    "test_sel_final.drop(columns=\"source\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#split train data\n",
    "train_sel_X = train_sel_final.drop(columns=[\"y\"])\n",
    "train_sel_Y = train_sel_final[\"y\"]\n",
    "test_sel_X = test_sel_final.drop(columns=[\"y\"])\n",
    "test_sel_Y = test_sel_final[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.986072188840414,\n",
       "  10.140100050363476,\n",
       "  1014.0100050363476,\n",
       "  35.296848777365014]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "rmf_sel = RandomForestRegressor(n_jobs = -1)\n",
    "model_metrics=calc_metrics_and_predict(rmf_sel,'Random Forest',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None, True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.986072188840414,\n",
       "  10.140100050363476,\n",
       "  1014.0100050363476,\n",
       "  35.296848777365014],\n",
       " 'linear_reg': [59.74564719129952,\n",
       "  46.115857051744584,\n",
       "  4611.585705174459,\n",
       "  60.00001900555336]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "        \n",
    "model_metrics=calc_metrics_and_predict(linear_model,'linear_reg',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.0939e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.24471e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.19375e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.06782e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.25877e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.18114e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.28275e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.20072e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.19171e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.18771e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.48929e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.38738e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.43196e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.5174e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.36215e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.61341e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.35373e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.4013e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.38327e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.28139e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.7337e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.58086e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.64773e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.77589e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.54304e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.24362e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.53042e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.60174e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=3.57478e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.37497e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.97798e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.77422e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.86335e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.03422e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.72377e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.67571e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.16134e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.80205e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.7661e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.46843e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.22211e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.96742e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.07883e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.29243e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=2.77184e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.90435e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.30507e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.88338e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.00221e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=5.95728e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.56178e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.46609e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.16049e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.29416e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.55047e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.65339e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.08485e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.83843e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.05965e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.20227e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.14836e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.65501e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.70994e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.35343e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.50936e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.80838e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=4.9672e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.26518e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.82806e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.23578e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.40212e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.33927e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=8.74813e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.95363e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.54623e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.7244e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.00662e-16): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=6.59531e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.44537e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.045e-16): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.41177e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.60192e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 : 47.61844522770131\n",
      "0.5 : 47.618420745941535\n",
      "0.75 : 47.618397470270914\n",
      "1.0 : 47.618375041002224\n",
      "1.25 : 47.618353270460496\n",
      "1.5 : 47.61833205061826\n",
      "1.75 : 47.618311314329375\n",
      "2.0 : 47.618291017158604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=9.53005e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Regularization technique\n",
    "from sklearn.linear_model import Ridge, Lasso \n",
    "\n",
    "# List to maintain the different cross-validation scores \n",
    "cross_val_scores_ridge = [] \n",
    "  \n",
    "# List to maintain the different values of alpha \n",
    "alpha = [] \n",
    "  \n",
    "# Loop to compute the different values of cross-validation scores \n",
    "for i in range(1, 9): \n",
    "    ridgeModel = Ridge(alpha = i * 0.25) \n",
    "    ridgeModel.fit(train_X, train_Y) \n",
    "    scores = cross_val_score(ridgeModel, train_X, train_Y, cv = 10,scoring='neg_mean_squared_error') \n",
    "    avg_cross_val_score = np.mean(np.sqrt(np.abs(scores)))\n",
    "    cross_val_scores_ridge.append(avg_cross_val_score) \n",
    "    alpha.append(i * 0.25) \n",
    "  \n",
    "# Loop to print the different values of cross-validation scores \n",
    "for i in range(0, len(alpha)): \n",
    "    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.88810058707255,\n",
       "  10.12515281820688,\n",
       "  1012.515281820688,\n",
       "  35.299715048060335],\n",
       " 'linear_reg': [59.746683267028835,\n",
       "  46.1167062280611,\n",
       "  4611.670622806109,\n",
       "  60.00107676482412],\n",
       " 'regularization': [59.74668327778253,\n",
       "  46.11680228063031,\n",
       "  4611.680228063031,\n",
       "  60.001079659914964]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building ridge model\n",
    "ridgeModel = Ridge(alpha = 1 * 0.25) \n",
    "model_metrics=calc_metrics_and_predict(ridgeModel,'regularization',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling applied\n",
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.986072188840414,\n",
       "  10.140100050363476,\n",
       "  1014.0100050363476,\n",
       "  35.296848777365014],\n",
       " 'linear_reg': [59.74564719129952,\n",
       "  46.115857051744584,\n",
       "  4611.585705174459,\n",
       "  60.00001900555336],\n",
       " 'KNN': [32.670272760144236,\n",
       "  23.695125000000004,\n",
       "  2369.5125000000003,\n",
       "  46.86701522282912]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict on testing data:\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors = 3)\n",
    "model_metrics=calc_metrics_and_predict(neigh,'KNN',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,StandardScaler(),True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.986072188840414,\n",
       "  10.140100050363476,\n",
       "  1014.0100050363476,\n",
       "  35.296848777365014],\n",
       " 'linear_reg': [59.74564719129952,\n",
       "  46.115857051744584,\n",
       "  4611.585705174459,\n",
       "  60.00001900555336],\n",
       " 'KNN': [32.670272760144236,\n",
       "  23.695125000000004,\n",
       "  2369.5125000000003,\n",
       "  46.86701522282912],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB=GaussianNB()\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(NB,'NB_Gaussian',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f830599a54c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mNB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalc_metrics_and_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NB_MultinomialNB'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sel_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_sel_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sel_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_sel_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-b7e8574b5144>\u001b[0m in \u001b[0;36mcalc_metrics_and_predict\u001b[1;34m(model, model_label, train_X, test_X, train_Y, test_Y, test_final, scaler, cv)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fit data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0myhat_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    608\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    609\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB=MultinomialNB()\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(NB,'NB_MultinomialNB',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.986072188840414,\n",
       "  10.140100050363476,\n",
       "  1014.0100050363476,\n",
       "  35.296848777365014],\n",
       " 'linear_reg': [59.74564719129952,\n",
       "  46.115857051744584,\n",
       "  4611.585705174459,\n",
       "  60.00001900555336],\n",
       " 'KNN': [32.670272760144236,\n",
       "  23.695125000000004,\n",
       "  2369.5125000000003,\n",
       "  46.86701522282912],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823],\n",
       " 'NB_BernoulliNB': [66.14832641495929,\n",
       "  48.9825375,\n",
       "  4898.25375,\n",
       "  66.17019433113015]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BL=BernoulliNB()\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(BL,'NB_BernoulliNB',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.88810058707255,\n",
       "  10.12515281820688,\n",
       "  1012.515281820688,\n",
       "  35.299715048060335],\n",
       " 'linear_reg': [59.746683267028835,\n",
       "  46.1167062280611,\n",
       "  4611.670622806109,\n",
       "  60.00107676482412],\n",
       " 'regularization': [59.74668327778253,\n",
       "  46.11680228063031,\n",
       "  4611.680228063031,\n",
       "  60.001079659914964],\n",
       " 'KNN': [32.670046572595446, 23.6962125, 2369.62125, 46.863731538349164],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823],\n",
       " 'NB_BernoulliNB': [66.14832641495929,\n",
       "  48.9825375,\n",
       "  4898.25375,\n",
       "  66.17019433113015],\n",
       " 'Decision_Tree': [29.305457107709305,\n",
       "  21.22925408716651,\n",
       "  2122.925408716651,\n",
       "  43.4572910645188]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf=DecisionTreeRegressor(criterion='mse', max_depth=100, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=5, min_samples_split=8, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')\n",
    "\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(clf,'Decision_Tree',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n",
      "Cross-Validation score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.88810058707255,\n",
       "  10.12515281820688,\n",
       "  1012.515281820688,\n",
       "  35.299715048060335],\n",
       " 'linear_reg': [59.746683267028835,\n",
       "  46.1167062280611,\n",
       "  4611.670622806109,\n",
       "  60.00107676482412],\n",
       " 'regularization': [59.74668327778253,\n",
       "  46.11680228063031,\n",
       "  4611.680228063031,\n",
       "  60.001079659914964],\n",
       " 'KNN': [32.670046572595446, 23.6962125, 2369.62125, 46.863731538349164],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823],\n",
       " 'NB_BernoulliNB': [66.14832641495929,\n",
       "  48.9825375,\n",
       "  4898.25375,\n",
       "  66.17019433113015],\n",
       " 'Decision_Tree': [29.305457107709305,\n",
       "  21.22925408716651,\n",
       "  2122.925408716651,\n",
       "  43.4572910645188],\n",
       " 'Adaboost': [28.64807256773893,\n",
       "  20.758000432045943,\n",
       "  2075.800043204594,\n",
       "  43.14825518817853]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada boost classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor\n",
    "#dtree = DecisionTreeClassifier(criterion='',max_depth=1)\n",
    "\n",
    "adabst_fit = AdaBoostRegressor(base_estimator= clf,n_estimators=5000,learning_rate=0.05,random_state=42)\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(clf,'Adaboost',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,True)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "predict data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.88810058707255,\n",
       "  10.12515281820688,\n",
       "  1012.515281820688,\n",
       "  35.299715048060335],\n",
       " 'linear_reg': [59.746683267028835,\n",
       "  46.1167062280611,\n",
       "  4611.670622806109,\n",
       "  60.00107676482412],\n",
       " 'regularization': [59.74668327778253,\n",
       "  46.11680228063031,\n",
       "  4611.680228063031,\n",
       "  60.001079659914964],\n",
       " 'KNN': [32.670046572595446, 23.6962125, 2369.62125, 46.863731538349164],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823],\n",
       " 'NB_BernoulliNB': [66.14832641495929,\n",
       "  48.9825375,\n",
       "  4898.25375,\n",
       "  66.17019433113015],\n",
       " 'Decision_Tree': [29.305457107709305,\n",
       "  21.22925408716651,\n",
       "  2122.925408716651,\n",
       "  43.4572910645188],\n",
       " 'Adaboost': [28.64807256773893,\n",
       "  20.758000432045943,\n",
       "  2075.800043204594,\n",
       "  43.14825518817853],\n",
       " 'Gradient_boosting': [34.305741522870676,\n",
       "  21.124645376803215,\n",
       "  2112.4645376803214,\n",
       "  None]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradientboost Classifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbc_fit = GradientBoostingRegressor(loss='quantile',learning_rate=0.05,n_estimators=200,min_samples_split=8,min_samples_leaf=5,max_depth=100,random_state=42,max_features='log2')\n",
    "\n",
    "#gbc_fit = GradientBoostingRegressor(base_estimator= clf,n_estimators=5000,learning_rate=0.05,random_state=42)\n",
    "\n",
    "    \n",
    "model_metrics=calc_metrics_and_predict(gbc_fit,'Gradient_boosting',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,False)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit data\n",
      "[22:19:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': [14.88810058707255,\n",
       "  10.12515281820688,\n",
       "  1012.515281820688,\n",
       "  35.299715048060335],\n",
       " 'linear_reg': [59.746683267028835,\n",
       "  46.1167062280611,\n",
       "  4611.670622806109,\n",
       "  60.00107676482412],\n",
       " 'regularization': [59.74668327778253,\n",
       "  46.11680228063031,\n",
       "  4611.680228063031,\n",
       "  60.001079659914964],\n",
       " 'KNN': [32.670046572595446, 23.6962125, 2369.62125, 46.863731538349164],\n",
       " 'NB_Gaussian': [160.91086993270528,\n",
       "  134.0323875,\n",
       "  13403.23875,\n",
       "  158.18098792110823],\n",
       " 'NB_BernoulliNB': [66.14832641495929,\n",
       "  48.9825375,\n",
       "  4898.25375,\n",
       "  66.17019433113015],\n",
       " 'Decision_Tree': [29.305457107709305,\n",
       "  21.22925408716651,\n",
       "  2122.925408716651,\n",
       "  43.4572910645188],\n",
       " 'Adaboost': [28.64807256773893,\n",
       "  20.758000432045943,\n",
       "  2075.800043204594,\n",
       "  43.14825518817853],\n",
       " 'Gradient_boosting': [34.305741522870676,\n",
       "  21.124645376803215,\n",
       "  2112.4645376803214,\n",
       "  None],\n",
       " 'XGBoosting': [7.607477604226721, 5.535454089736938, 553.5454089736938, None]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xgboost Classifier\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_fit = xgb.XGBRegressor(learning_rate=0.05,n_estimators=100,min_samples_split=8,min_samples_leaf=5,max_depth=100,random_state=42,max_features='log2' )\n",
    "\n",
    "\n",
    "\n",
    "model_metrics=calc_metrics_and_predict(xgb_fit,'XGBoosting',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,False)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "\n",
    "# Get your data\n",
    "\n",
    "# Initialize 1st level models\n",
    "\n",
    "# Get your stacking features in a single line\n",
    "#S_train, S_test = stacking(models, X_train, y_train, X_test, regression = True, verbose = 2)\n",
    "\n",
    "# Use 2nd level model with stacking features\n",
    "#Complete examples\n",
    "#Regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from vecstack import stacking\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfm=RandomForestRegressor(random_state = 0, criterion='mse',n_jobs = -1, \n",
    "        n_estimators = 100, max_depth = None,min_samples_leaf=1,min_samples_split=2)\n",
    "\n",
    "#model_metrics=calc_metrics_and_predict(rfm,'Random_forest',train_X,test_X,train_Y,test_Y,test_final,None,True)\n",
    "#model_metrics\n",
    "\n",
    "# Caution! All models and parameter values are just \n",
    "# demonstrational and shouldn't be considered as recommended.\n",
    "# Initialize 1st level models.\n",
    "models = [\n",
    "    linear_model,\n",
    "    neigh,\n",
    "    rfm,\n",
    "#    xgb_fit\n",
    "    ]\n",
    "    \n",
    "# Compute stacking features\n",
    "S_train, S_test = stacking(models, train_sel_X, train_sel_Y, test_sel_X, \n",
    "    regression = True, metric = mean_absolute_error, n_folds = 4, \n",
    "    shuffle = True, random_state = 0, verbose = 2)\n",
    "\n",
    "# Initialize 2nd level model\n",
    "#model = XGBRegressor(seed = 0, n_jobs = -1, learning_rate = 0.1,     n_estimators = 100)\n",
    "model_stacking= xgb_fit\n",
    "\n",
    "# Fit 2nd level model\n",
    "model_stacking = model_stacking.fit(S_train, train_sel_Y)\n",
    "\n",
    "# Predict\n",
    "y_pred = model_stacking.predict(S_train)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_absolute_error(train_sel_Y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics=calc_metrics_and_predict(model_stacking,'Stacking',train_sel_X,test_sel_X,train_sel_Y,test_sel_Y,test_final,None,False)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model for the neural network. We choose a hidden layer of 10 neurons. The lesser number of neurons helps to eliminate the redundancies in the data and select the more important features.\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(21, input_dim=21, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model. We use the the logarithmic loss function, and the Adam gradient optimizer.\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for building the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis values are strings. Changing them into numerical values using LabelEncoder.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_sel_Y)\n",
    "encoded_Y = encoder.transform(train_sel_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "W0918 09:52:59.778506 12380 deprecation_wrapper.py:119] From C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0918 09:52:59.884281 12380 deprecation_wrapper.py:119] From C:\\Users\\Nagi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -11475050.60% (10477.67%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using standardized dataset. \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_baseline, epochs=30, batch_size=100, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(pipeline, train_sel_X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
